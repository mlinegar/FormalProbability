/-
# FormalProbability/DSL/AsymptoticTheory.lean

## Paper Reference: Section 3.2, Proposition 1, Appendix OA.7

This file formalizes the asymptotic theory of the DSL estimator:
- Consistency: Œ≤ÃÇ_DSL ‚Üí Œ≤* as N ‚Üí ‚àû
- Asymptotic normality: ‚àöN(Œ≤ÃÇ_DSL - Œ≤*) ‚Üíd N(0, V)
- Variance formula (sandwich estimator)

### Main Results

**Proposition 1 (Asymptotic Properties)**

Under Assumption 1 (design-based sampling) and standard regularity conditions:

1. **Consistency:** Œ≤ÃÇ_DSL ‚Üíp Œ≤* as N ‚Üí ‚àû
2. **Asymptotic Normality:** ‚àöN(Œ≤ÃÇ_DSL - Œ≤*) ‚Üíd N(0, V)

where V is the sandwich variance matrix.

### Variance Formula (Equation OA.7)

V = S_V‚Åª¬π ¬∑ E[mÃÉ(D; Œ≤*) mÃÉ(D; Œ≤*)'] ¬∑ S_V‚Åª¬π'

where S_V = E[‚àÇmÃÉ/‚àÇŒ≤] evaluated at Œ≤*.
-/

import FormalProbability.DSL.DSLEstimator
import FormalProbability.DSL.CrossFitting
import FormalProbability.DSL.BiasAnalysis
import Mathlib.MeasureTheory.Measure.Typeclasses.Probability
import Mathlib.MeasureTheory.Function.ConvergenceInDistribution
import Mathlib.MeasureTheory.Function.ConvergenceInMeasure

set_option linter.mathlibStandardSet false

open scoped BigOperators
open scoped Classical
open scoped Topology
open MeasureTheory

set_option maxHeartbeats 0
set_option maxRecDepth 4000
set_option relaxedAutoImplicit false
set_option autoImplicit false

noncomputable section

namespace DSL

/-!
## Regularity Conditions
-/

/-- Standard regularity conditions for asymptotic normality.
    These are the conditions from M-estimation theory. -/
structure RegularityConditions (Data : Type*) (d : ‚Ñï) where
  /-- The parameter space is open -/
  param_space_open : True  -- Placeholder
  /-- The moment function is twice continuously differentiable -/
  moment_smooth : True  -- Placeholder
  /-- The Jacobian E[‚àÇm/‚àÇŒ≤] is invertible at Œ≤* -/
  jacobian_invertible : True  -- Placeholder
  /-- The second moment E[m m'] exists and is finite -/
  second_moment_finite : True  -- Placeholder
  /-- Uniform convergence of sample moments -/
  uniform_convergence : True  -- Placeholder

/-- Cross-fitting regularity conditions (placeholder). -/
structure CrossFittingConditions {Œπ Obs Con Mis : Type*} [Fintype Œπ]
    (cf : CrossFit Œπ Obs Con Mis) : Prop where
  no_leakage : True  -- Predictor for each fold is trained on other folds

/-!
## Consistency
-/

/-- Convergence in probability (mathlib: `TendstoInMeasure`). -/
def ConvergesInProbability {Œ© : Type*} [MeasurableSpace Œ©]
    (Œº : Measure Œ©) [IsProbabilityMeasure Œº]
    {E : Type*} [PseudoMetricSpace E]
    (seq : ‚Ñï ‚Üí Œ© ‚Üí E) (limit : Œ© ‚Üí E) : Prop :=
  MeasureTheory.TendstoInMeasure Œº seq Filter.atTop limit

/-- Placeholder predicate for a normal limit.

Mathlib does not yet provide a packaged multivariate normal distribution,
so we record normality as an explicit assumption. -/
structure NormalLimit {Œ© : Type*} [MeasurableSpace Œ©]
    (Œº : Measure Œ©) [IsProbabilityMeasure Œº] {d : ‚Ñï}
    (Z : Œ© ‚Üí Fin d ‚Üí ‚Ñù) (mean : Fin d ‚Üí ‚Ñù)
    (variance : Matrix (Fin d) (Fin d) ‚Ñù) : Prop where
  placeholder : True := by trivial

/-- Convergence in distribution to a normal limit (mathlib: `TendstoInDistribution`). -/
def ConvergesInDistributionToNormal {Œ© : Type*} [MeasurableSpace Œ©]
    (Œº : Measure Œ©) [IsProbabilityMeasure Œº] {d : ‚Ñï}
    (seq : ‚Ñï ‚Üí Œ© ‚Üí Fin d ‚Üí ‚Ñù)
    (mean : Fin d ‚Üí ‚Ñù)
    (variance : Matrix (Fin d) (Fin d) ‚Ñù) : Prop :=
  ‚àÉ Z : Œ© ‚Üí Fin d ‚Üí ‚Ñù,
    NormalLimit Œº Z mean variance ‚àß
      MeasureTheory.TendstoInDistribution seq Filter.atTop Z Œº

/-- Asymptotic coverage of a confidence interval sequence. -/
def AsymptoticCoverage {Œ© : Type*} [MeasurableSpace Œ©]
    (Œº : Measure Œ©) [IsProbabilityMeasure Œº] {d : ‚Ñï}
    (CI_seq : ‚Ñï ‚Üí Œ© ‚Üí Fin d ‚Üí ‚Ñù √ó ‚Ñù)
    (Œ≤_star : Fin d ‚Üí ‚Ñù)
    (Œ± : ‚Ñù) : Prop :=
  ‚àÄ i, Filter.Tendsto
    (fun n =>
      Œº {œâ | Œ≤_star i ‚àà Set.Icc (CI_seq n œâ i).1 (CI_seq n œâ i).2})
    Filter.atTop (ùìù (ENNReal.ofReal (1 - Œ±)))

/-- Wald-style coverage derived from asymptotic normality (assumption bundle). -/
structure CoverageAxioms {Œ© : Type*} [MeasurableSpace Œ©]
    (Œº : Measure Œ©) [IsProbabilityMeasure Œº] (d : ‚Ñï) : Prop where
  coverage_of_asymptotic_normal :
    ‚àÄ (centered_scaled_seq : ‚Ñï ‚Üí Œ© ‚Üí Fin d ‚Üí ‚Ñù)
      (CI_seq : ‚Ñï ‚Üí Œ© ‚Üí Fin d ‚Üí ‚Ñù √ó ‚Ñù)
      (Œ≤_star : Fin d ‚Üí ‚Ñù)
      (Œ± : ‚Ñù)
      (V : Matrix (Fin d) (Fin d) ‚Ñù),
      ConvergesInDistributionToNormal Œº centered_scaled_seq (fun _ => 0) V ‚Üí
      AsymptoticCoverage Œº CI_seq Œ≤_star Œ±

/-!
## Sample Moments and Estimators
-/

/-- Sample mean of a moment function over a finite dataset. -/
def sampleMoment {Data : Type*} {d : ‚Ñï}
    (m : MomentFunction Data d)
    (data : List Data)
    (Œ≤ : Fin d ‚Üí ‚Ñù) : Fin d ‚Üí ‚Ñù :=
  let N := data.length
  fun j => (data.foldl (fun acc D => acc + m D Œ≤ j) 0) / N

/-- A (sample) M-estimator solves the sample moment condition. -/
def IsMEstimator {Data : Type*} {d : ‚Ñï}
    (m : MomentFunction Data d)
    (data : List Data)
    (Œ≤ : Fin d ‚Üí ‚Ñù) : Prop :=
  sampleMoment m data Œ≤ = 0

/-- An estimator sequence solves the sample moment condition at each n. -/
def IsMEstimatorSeq {Data : Type*} {d : ‚Ñï}
    (m : MomentFunction Data d)
    {Œ© : Type*}
    (data_seq : ‚Ñï ‚Üí Œ© ‚Üí List Data)
    (Œ≤_hat_seq : ‚Ñï ‚Üí Œ© ‚Üí Fin d ‚Üí ‚Ñù) : Prop :=
  ‚àÄ n œâ, IsMEstimator m (data_seq n œâ) (Œ≤_hat_seq n œâ)

/-- DSL moment function lifted to a single data record. -/
def DSLMomentFromData {Obs Mis : Type*} {d : ‚Ñï}
    (m : MomentFunction (Obs √ó Mis) d)
    (D : Obs √ó Mis √ó Mis √ó SamplingIndicator √ó ‚Ñù)
    (Œ≤ : Fin d ‚Üí ‚Ñù) : Fin d ‚Üí ‚Ñù :=
  match D with
  | ‚ü®d_obs, d_mis_pred, d_mis_true, R, œÄ‚ü© =>
      DSLMoment m d_obs d_mis_pred d_mis_true R œÄ Œ≤

/-!
## Oracle Target
-/

/-- Oracle moment using the true missing values from a full DSL data record. -/
def TrueMomentFromFullData {Obs Mis : Type*} {d : ‚Ñï}
    (m : MomentFunction (Obs √ó Mis) d) :
    MomentFunction (Obs √ó Mis √ó Mis √ó SamplingIndicator √ó ‚Ñù) d :=
  fun D Œ≤ =>
    match D with
    | ‚ü®d_obs, _d_mis_pred, d_mis_true, _R, _œÄ‚ü© =>
        m (d_obs, d_mis_true) Œ≤

/-- Oracle target parameter: solves the true moment condition. -/
def OracleTarget {Obs Mis : Type*} {d : ‚Ñï}
    (m : MomentFunction (Obs √ó Mis) d)
    (E : ((Obs √ó Mis √ó Mis √ó SamplingIndicator √ó ‚Ñù) ‚Üí Fin d ‚Üí ‚Ñù) ‚Üí Fin d ‚Üí ‚Ñù)
    (Œ≤ : Fin d ‚Üí ‚Ñù) : Prop :=
  MomentUnbiased (TrueMomentFromFullData m) E Œ≤

/-!
## Generic M-Estimation Axioms
-/

/-- Abstract M-estimation asymptotic results, used as axioms in this formalization. -/
structure MEstimationAxioms (Œ© Data : Type*) [MeasurableSpace Œ©]
    (Œº : Measure Œ©) [IsProbabilityMeasure Œº] (d : ‚Ñï) where
  /-- Expectation operator for moments. -/
  E : (Data ‚Üí Fin d ‚Üí ‚Ñù) ‚Üí Fin d ‚Üí ‚Ñù
  /-- Consistency for any estimator sequence solving the sample moment equation. -/
  consistent :
    ‚àÄ (m : MomentFunction Data d) (Œ≤_star : Fin d ‚Üí ‚Ñù)
      (data_seq : ‚Ñï ‚Üí Œ© ‚Üí List Data) (Œ≤_hat_seq : ‚Ñï ‚Üí Œ© ‚Üí Fin d ‚Üí ‚Ñù),
      MomentUnbiased m E Œ≤_star ‚Üí
      RegularityConditions Data d ‚Üí
      IsMEstimatorSeq m data_seq Œ≤_hat_seq ‚Üí
      ConvergesInProbability Œº Œ≤_hat_seq (fun _ => Œ≤_star)
  /-- Asymptotic normality for centered/scaled estimator sequences. -/
  asymptotic_normal :
    ‚àÄ (m : MomentFunction Data d) (Œ≤_star : Fin d ‚Üí ‚Ñù) (V : Matrix (Fin d) (Fin d) ‚Ñù)
      (centered_scaled_seq : ‚Ñï ‚Üí Œ© ‚Üí Fin d ‚Üí ‚Ñù),
      MomentUnbiased m E Œ≤_star ‚Üí
      RegularityConditions Data d ‚Üí
      ConvergesInDistributionToNormal Œº centered_scaled_seq (fun _ => 0) V

/-- DSL consistency theorem.

    Under Assumption 1 and regularity conditions, the DSL estimator
    converges in probability to the true parameter Œ≤*.

    The key insight is that E[mÃÉ(D; Œ≤*)] = 0 because the design-adjusted
    moment is unbiased, so by the law of large numbers,
    (1/N)‚àëmÃÉ(Di; Œ≤) ‚Üí E[mÃÉ(D; Œ≤)] and the unique zero is at Œ≤*. -/
theorem DSL_consistent
    {Œ© : Type*} [MeasurableSpace Œ©] (Œº : Measure Œ©) [IsProbabilityMeasure Œº]
    {Obs Mis Con : Type*} {d : ‚Ñï}
    (axioms : MEstimationAxioms Œ© (Obs √ó Mis √ó Mis √ó SamplingIndicator √ó ‚Ñù) Œº d)
    (dbs : DesignBasedSampling Obs Mis Con)
    (m : MomentFunction (Obs √ó Mis) d)
    (Œ≤_star : Fin d ‚Üí ‚Ñù)
    (reg : RegularityConditions (Obs √ó Mis √ó Mis √ó SamplingIndicator √ó ‚Ñù) d)
    (h_unbiased : MomentUnbiased (DSLMomentFromData m) axioms.E Œ≤_star)
    (data_seq : ‚Ñï ‚Üí Œ© ‚Üí List (Obs √ó Mis √ó Mis √ó SamplingIndicator √ó ‚Ñù))
    (Œ≤_hat_seq : ‚Ñï ‚Üí Œ© ‚Üí Fin d ‚Üí ‚Ñù)
    (h_est : IsMEstimatorSeq (DSLMomentFromData m) data_seq Œ≤_hat_seq)
    : ConvergesInProbability Œº Œ≤_hat_seq (fun _ => Œ≤_star) := by
  exact axioms.consistent (DSLMomentFromData m) Œ≤_star data_seq Œ≤_hat_seq h_unbiased reg h_est

/-- Cross-fitted DSL consistency theorem (Appendix B.2). -/
theorem DSL_consistent_crossfit
    {Œ© : Type*} [MeasurableSpace Œ©] (Œº : Measure Œ©) [IsProbabilityMeasure Œº]
    {Œπ Obs Mis Con : Type*} [Fintype Œπ] {d : ‚Ñï}
    (axioms : MEstimationAxioms Œ© (Obs √ó Mis √ó Mis √ó SamplingIndicator √ó ‚Ñù) Œº d)
    (cf : CrossFit Œπ Obs Con Mis)
    (dbs : DesignBasedSampling Obs Mis Con)
    (m : MomentFunction (Obs √ó Mis) d)
    (Œ≤_star : Fin d ‚Üí ‚Ñù)
    (reg : RegularityConditions (Obs √ó Mis √ó Mis √ó SamplingIndicator √ó ‚Ñù) d)
    (cf_reg : CrossFittingConditions cf)
    (h_unbiased : MomentUnbiased (DSLMomentFromData m) axioms.E Œ≤_star)
    (data_seq : ‚Ñï ‚Üí Œ© ‚Üí List (Obs √ó Mis √ó Mis √ó SamplingIndicator √ó ‚Ñù))
    (Œ≤_hat_seq : ‚Ñï ‚Üí Œ© ‚Üí Fin d ‚Üí ‚Ñù)
    (h_est : IsMEstimatorSeq (DSLMomentFromData m) data_seq Œ≤_hat_seq)
    : ConvergesInProbability Œº Œ≤_hat_seq (fun _ => Œ≤_star) := by
  exact axioms.consistent (DSLMomentFromData m) Œ≤_star data_seq Œ≤_hat_seq h_unbiased reg h_est

/-!
## Asymptotic Normality
-/

/-- DSL asymptotic normality theorem (Proposition 1).

    Under Assumption 1 and regularity conditions:
    ‚àöN(Œ≤ÃÇ_DSL - Œ≤*) ‚Üíd N(0, V)

    where V is the sandwich variance matrix. -/
theorem DSL_asymptotic_normal
    {Œ© : Type*} [MeasurableSpace Œ©] (Œº : Measure Œ©) [IsProbabilityMeasure Œº]
    {Obs Mis Con : Type*} {d : ‚Ñï}
    (axioms : MEstimationAxioms Œ© (Obs √ó Mis √ó Mis √ó SamplingIndicator √ó ‚Ñù) Œº d)
    (dbs : DesignBasedSampling Obs Mis Con)
    (m : MomentFunction (Obs √ó Mis) d)
    (Œ≤_star : Fin d ‚Üí ‚Ñù)
    (V : Matrix (Fin d) (Fin d) ‚Ñù)
    (reg : RegularityConditions (Obs √ó Mis √ó Mis √ó SamplingIndicator √ó ‚Ñù) d)
    (h_unbiased : MomentUnbiased (DSLMomentFromData m) axioms.E Œ≤_star)
    : ‚àÄ (centered_scaled_seq : ‚Ñï ‚Üí Œ© ‚Üí Fin d ‚Üí ‚Ñù),
      -- ‚àöN(Œ≤ÃÇ_N - Œ≤*) where Œ≤ÃÇ_N is the DSL estimator
      ConvergesInDistributionToNormal Œº centered_scaled_seq (fun _ => 0) V := by
  intro seq
  exact axioms.asymptotic_normal (DSLMomentFromData m) Œ≤_star V seq h_unbiased reg

/-- Cross-fitted DSL asymptotic normality theorem (Appendix B.2). -/
theorem DSL_asymptotic_normal_crossfit
    {Œ© : Type*} [MeasurableSpace Œ©] (Œº : Measure Œ©) [IsProbabilityMeasure Œº]
    {Œπ Obs Mis Con : Type*} [Fintype Œπ] {d : ‚Ñï}
    (axioms : MEstimationAxioms Œ© (Obs √ó Mis √ó Mis √ó SamplingIndicator √ó ‚Ñù) Œº d)
    (cf : CrossFit Œπ Obs Con Mis)
    (dbs : DesignBasedSampling Obs Mis Con)
    (m : MomentFunction (Obs √ó Mis) d)
    (Œ≤_star : Fin d ‚Üí ‚Ñù)
    (V : Matrix (Fin d) (Fin d) ‚Ñù)
    (reg : RegularityConditions (Obs √ó Mis √ó Mis √ó SamplingIndicator √ó ‚Ñù) d)
    (cf_reg : CrossFittingConditions cf)
    (h_unbiased : MomentUnbiased (DSLMomentFromData m) axioms.E Œ≤_star)
    : ‚àÄ (centered_scaled_seq : ‚Ñï ‚Üí Œ© ‚Üí Fin d ‚Üí ‚Ñù),
      ConvergesInDistributionToNormal Œº centered_scaled_seq (fun _ => 0) V := by
  intro seq
  exact axioms.asymptotic_normal (DSLMomentFromData m) Œ≤_star V seq h_unbiased reg

/-!
## Variance Formula
-/

/-- Jacobian matrix of the moment function: E[‚àÇm/‚àÇŒ≤] -/
def JacobianMatrix {Obs Mis : Type*} {d : ‚Ñï}
    (m : MomentFunction (Obs √ó Mis) d)
    (E : ((Obs √ó Mis) ‚Üí Matrix (Fin d) (Fin d) ‚Ñù) ‚Üí Matrix (Fin d) (Fin d) ‚Ñù)
    (Œ≤ : Fin d ‚Üí ‚Ñù) : Matrix (Fin d) (Fin d) ‚Ñù :=
  -- Placeholder: proper definition would involve differentiation
  fun _ _ => 0

/-- Meat matrix: E[mÃÉ mÃÉ'] -/
def MeatMatrix {Obs Mis : Type*} {d : ‚Ñï}
    (m_tilde : (Obs √ó Mis) ‚Üí Fin d ‚Üí ‚Ñù)
    (E : ((Obs √ó Mis) ‚Üí Matrix (Fin d) (Fin d) ‚Ñù) ‚Üí Matrix (Fin d) (Fin d) ‚Ñù)
    : Matrix (Fin d) (Fin d) ‚Ñù :=
  E (fun data => fun i j => m_tilde data i * m_tilde data j)

/-- Sandwich variance matrix: V = S‚Åª¬π ¬∑ M ¬∑ S‚Åª¬π'

    This is the standard sandwich estimator for M-estimators.
    For DSL, the meat matrix M uses the design-adjusted moments mÃÉ. -/
def SandwichVariance {d : ‚Ñï}
    (S_inv : Matrix (Fin d) (Fin d) ‚Ñù)  -- S_V‚Åª¬π
    (M : Matrix (Fin d) (Fin d) ‚Ñù)       -- E[mÃÉ mÃÉ']
    : Matrix (Fin d) (Fin d) ‚Ñù :=
  S_inv * M * S_inv.transpose

/-!
## Variance Decomposition
-/

/-- Entrywise matrix order (simple PSD-like proxy). -/
def MatrixLE {d : ‚Ñï} (A B : Matrix (Fin d) (Fin d) ‚Ñù) : Prop :=
  ‚àÄ i j, A i j ‚â§ B i j

lemma matrixLE_add {d : ‚Ñï} {A B C D : Matrix (Fin d) (Fin d) ‚Ñù}
    (h1 : MatrixLE A B) (h2 : MatrixLE C D) : MatrixLE (A + C) (B + D) := by
  intro i j
  simpa using add_le_add (h1 i j) (h2 i j)

lemma matrixLE_smul {d : ‚Ñï} {A B : Matrix (Fin d) (Fin d) ‚Ñù}
    (c : ‚Ñù) (hc : 0 ‚â§ c) (h : MatrixLE A B) : MatrixLE (c ‚Ä¢ A) (c ‚Ä¢ B) := by
  intro i j
  -- Scalar multiplication is entrywise.
  simpa using mul_le_mul_of_nonneg_left (h i j) hc

/-- Variance decomposition for DSL.

    The variance of the DSL estimator can be decomposed as:
    V_DSL = V_full + (1/œÄ - 1) ¬∑ V_correction

    where:
    - V_full is the variance if all documents were expert-coded
    - V_correction accounts for using predictions instead of true labels
    - As prediction accuracy improves, V_correction decreases

    This shows that better predictions lead to smaller standard errors. -/
structure VarianceDecomposition {d : ‚Ñï} where
  /-- Variance with full expert coding (n = N) -/
  V_full : Matrix (Fin d) (Fin d) ‚Ñù
  /-- Correction variance from using predictions -/
  V_correction : Matrix (Fin d) (Fin d) ‚Ñù
  /-- Sampling probability -/
  œÄ : ‚Ñù
  /-- Total DSL variance -/
  V_DSL : Matrix (Fin d) (Fin d) ‚Ñù
  /-- Decomposition relation -/
  h_decomp : V_DSL = V_full + ((1/œÄ - 1) : ‚Ñù) ‚Ä¢ V_correction

/-- Better predictions reduce variance.

    If the prediction error variance decreases, V_correction decreases,
    leading to smaller overall variance V_DSL.

    This formalizes the efficiency property of DSL: better LLMs ‚Üí smaller SEs. -/
theorem better_predictions_smaller_variance {d : ‚Ñï}
    (vd1 vd2 : VarianceDecomposition (d := d))
    -- Same œÄ and V_full
    (h_œÄ : vd1.œÄ = vd2.œÄ)
    (h_full : vd1.V_full = vd2.V_full)
    -- V_correction is "smaller" for vd2 (in positive semidefinite sense)
    -- Placeholder: proper definition would use matrix ordering
    (h_smaller : MatrixLE vd2.V_correction vd1.V_correction)
    (h_factor_nonneg : (1 / vd1.œÄ - 1 : ‚Ñù) ‚â• 0)
    : MatrixLE vd2.V_DSL vd1.V_DSL := by
  have h_full_le : MatrixLE vd2.V_full vd1.V_full := by
    intro i j
    simp [h_full]
  have h_corr_le :
      MatrixLE ((1 / vd2.œÄ - 1 : ‚Ñù) ‚Ä¢ vd2.V_correction)
        ((1 / vd1.œÄ - 1 : ‚Ñù) ‚Ä¢ vd1.V_correction) := by
    have h_œÄ' : vd2.œÄ = vd1.œÄ := h_œÄ.symm
    simpa [h_œÄ'] using
      (matrixLE_smul (c := (1 / vd1.œÄ - 1 : ‚Ñù)) h_factor_nonneg h_smaller)
  have h_le :
      MatrixLE (vd2.V_full + ((1 / vd2.œÄ - 1 : ‚Ñù) ‚Ä¢ vd2.V_correction))
        (vd1.V_full + ((1 / vd1.œÄ - 1 : ‚Ñù) ‚Ä¢ vd1.V_correction)) :=
    matrixLE_add h_full_le h_corr_le
  simpa [vd1.h_decomp, vd2.h_decomp] using h_le

/-!
## Standard Error Formula
-/

/-- Standard error for the i-th coefficient -/
def standardError {d : ‚Ñï} (V : Matrix (Fin d) (Fin d) ‚Ñù) (i : Fin d) : ‚Ñù :=
  Real.sqrt (V i i)

/-- Confidence interval for the i-th coefficient -/
def confidenceInterval {d : ‚Ñï}
    (Œ≤_hat : Fin d ‚Üí ‚Ñù)
    (V : Matrix (Fin d) (Fin d) ‚Ñù)
    (N : ‚Ñï)
    (z_alpha : ‚Ñù)  -- Critical value (e.g., 1.96 for 95% CI)
    (i : Fin d) : ‚Ñù √ó ‚Ñù :=
  let se := standardError V i / Real.sqrt N
  (Œ≤_hat i - z_alpha * se, Œ≤_hat i + z_alpha * se)

/-- DSL confidence intervals have correct coverage.

    Under Assumption 1, the DSL confidence intervals achieve the
    nominal coverage rate asymptotically, regardless of prediction accuracy.

    This is the key advantage of DSL: valid inference without
    assumptions about prediction error structure. -/
theorem DSL_valid_coverage
    {Œ© : Type*} [MeasurableSpace Œ©] (Œº : Measure Œ©) [IsProbabilityMeasure Œº]
    {Obs Mis Con : Type*} {d : ‚Ñï}
    (axioms : MEstimationAxioms Œ© (Obs √ó Mis √ó Mis √ó SamplingIndicator √ó ‚Ñù) Œº d)
    (coverage_axioms : CoverageAxioms Œº d)
    (dbs : DesignBasedSampling Obs Mis Con)
    (m : MomentFunction (Obs √ó Mis) d)
    (Œ≤_star : Fin d ‚Üí ‚Ñù)
    (V : Matrix (Fin d) (Fin d) ‚Ñù)
    (reg : RegularityConditions (Obs √ó Mis √ó Mis √ó SamplingIndicator √ó ‚Ñù) d)
    (h_unbiased : MomentUnbiased (DSLMomentFromData m) axioms.E Œ≤_star)
    (CI_seq : ‚Ñï ‚Üí Œ© ‚Üí Fin d ‚Üí ‚Ñù √ó ‚Ñù)
    (Œ± : ‚Ñù)  -- Significance level
    (h_Œ± : 0 < Œ± ‚àß Œ± < 1)
    (centered_scaled_seq : ‚Ñï ‚Üí Œ© ‚Üí Fin d ‚Üí ‚Ñù)
    : AsymptoticCoverage Œº CI_seq Œ≤_star Œ± := by
  have h_norm :
      ConvergesInDistributionToNormal Œº centered_scaled_seq (fun _ => 0) V :=
    DSL_asymptotic_normal Œº axioms dbs m Œ≤_star V reg h_unbiased centered_scaled_seq
  exact coverage_axioms.coverage_of_asymptotic_normal centered_scaled_seq CI_seq Œ≤_star Œ± V h_norm

/-!
## Comparison with Naive Estimator
-/

/-- The naive estimator ignores prediction errors.

    Œ≤ÃÇ_naive solves (1/N)‚àëm(D^obs, DÃÇ^mis; Œ≤) = 0

    This is inconsistent unless E[m(D^obs, DÃÇ^mis; Œ≤*)] = E[m(D^obs, D^mis; Œ≤*)]
    which requires prediction errors to be uncorrelated with everything. -/
def NaiveEstimator {Obs Mis : Type*} {d : ‚Ñï}
    (m : MomentFunction (Obs √ó Mis) d)
    (data : List (Obs √ó Mis))  -- Only uses (d_obs, d_mis_pred)
    (Œ≤ : Fin d ‚Üí ‚Ñù) : Fin d ‚Üí ‚Ñù :=
  let N := data.length
  fun i => (data.foldl (fun acc ‚ü®d_obs, d_mis_pred‚ü© =>
    acc + m (d_obs, d_mis_pred) Œ≤ i) 0) / N

/-- Naive moment function on (d_obs, d_mis_pred, d_mis_true). -/
def PredMomentFromData {Obs Mis : Type*} {d : ‚Ñï}
    (m : MomentFunction (Obs √ó Mis) d) : MomentFunction (Obs √ó Mis √ó Mis) d :=
  fun D Œ≤ => m (D.1, D.2.1) Œ≤

/-- Oracle moment function using true missing values. -/
def TrueMomentFromData {Obs Mis : Type*} {d : ‚Ñï}
    (m : MomentFunction (Obs √ó Mis) d) : MomentFunction (Obs √ó Mis √ó Mis) d :=
  fun D Œ≤ => m (D.1, D.2.2) Œ≤

/-- Componentwise linearity of an expectation operator. -/
def ExpectationLinear {Data : Type*} {d : ‚Ñï}
    (E : (Data ‚Üí Fin d ‚Üí ‚Ñù) ‚Üí Fin d ‚Üí ‚Ñù) : Prop :=
  ‚àÄ (f g : Data ‚Üí Fin d ‚Üí ‚Ñù) (a b : ‚Ñù) (i : Fin d),
    E (fun D => fun j => a * f D j + b * g D j) i =
      a * E f i + b * E g i

/-- The naive estimator is biased unless very strong conditions hold.

    For the naive estimator to be consistent, we need:
    E[e | X] = 0 where e = ≈∂ - Y

    This requires errors to be uncorrelated with:
    - X (the covariates)
    - Y (the true outcome)
    - Any unobserved confounders U

    This almost never holds in practice. -/
theorem naive_estimator_biased_general
    {Obs Mis : Type*} {d : ‚Ñï}
    (m : MomentFunction (Obs √ó Mis) d)
    (E : ((Obs √ó Mis √ó Mis) ‚Üí Fin d ‚Üí ‚Ñù) ‚Üí Fin d ‚Üí ‚Ñù)
    (Œ≤_star : Fin d ‚Üí ‚Ñù)
    (h_true : MomentUnbiased (TrueMomentFromData m) E Œ≤_star)
    (h_bias : ‚àÉ i, MomentBias m E Œ≤_star i ‚â† 0)
    (hE_linear : ExpectationLinear E)
    : ¬¨ MomentUnbiased (PredMomentFromData m) E Œ≤_star := by
  intro h_pred
  rcases h_bias with ‚ü®i, h_nonzero‚ü©
  have h_bias_eq :
      MomentBias m E Œ≤_star i =
        E (fun D => fun j =>
          PredMomentFromData m D Œ≤_star j - TrueMomentFromData m D Œ≤_star j) i := by
    rfl
  have h_linear :
      E (fun D => fun j =>
        PredMomentFromData m D Œ≤_star j - TrueMomentFromData m D Œ≤_star j) i =
        E (fun D => PredMomentFromData m D Œ≤_star) i -
        E (fun D => TrueMomentFromData m D Œ≤_star) i := by
    -- Use linearity with a = 1, b = -1.
    have := hE_linear
      (fun D => PredMomentFromData m D Œ≤_star)
      (fun D => TrueMomentFromData m D Œ≤_star)
      1 (-1) i
    -- Simplify pointwise.
    simpa [sub_eq_add_neg, add_comm, add_left_comm, add_assoc, mul_comm, mul_left_comm, mul_assoc] using this
  have h_pred_zero : E (fun D => PredMomentFromData m D Œ≤_star) i = 0 := h_pred i
  have h_true_zero : E (fun D => TrueMomentFromData m D Œ≤_star) i = 0 := h_true i
  have h_bias_zero : MomentBias m E Œ≤_star i = 0 := by
    calc
      MomentBias m E Œ≤_star i
          = E (fun D => fun j =>
              PredMomentFromData m D Œ≤_star j - TrueMomentFromData m D Œ≤_star j) i := h_bias_eq
      _ = E (fun D => PredMomentFromData m D Œ≤_star) i -
          E (fun D => TrueMomentFromData m D Œ≤_star) i := h_linear
      _ = 0 := by simp [h_pred_zero, h_true_zero]
  exact h_nonzero h_bias_zero

end DSL

end
